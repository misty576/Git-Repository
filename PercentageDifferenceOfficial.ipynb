{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-settlement risk is the possibility that one party in a contract will fail to meet its obligations under that contract, resulting in a default before the settlement date. \n",
    "# mark to market (MTM) - The present value of all the payments that a party is expecting to receive, less those it is obliged to make\n",
    "# ctb = contribution\n",
    "# there will also be BASELINE RESETS = the exposure for the orginal baseline will be recalculated due to changing market conditions\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "# We define the exposure (MTM) calculator\n",
    "def currentExposure(mtm):\n",
    "    return max(0,mtm)\n",
    "\n",
    "# We calculate the notional\n",
    "def addOn(notional, addOnFactor):\n",
    "    return notional*addOnFactor\n",
    "\n",
    "# The total exposure is the sum of the two above functions\n",
    "def totalExposure(mtm, notional, addOnFactor):\n",
    "    currExp = currentExposure(mtm)\n",
    "    currAddOn = addOn(notional, addOnFactor)\n",
    "\n",
    "    return currExp + currAddOn\n",
    "\n",
    "# The brute force takes all the impacts, sums them together, and calculates the bulk exposure.\n",
    "def psrBruteForce(position, impacts, addOnFactor):\n",
    "    \n",
    "    # For each step, we sum all the impacts into a variable called 'total' and calculate the exposure.\n",
    "\n",
    "    totalMtm = position[0] + np.sum(impacts[:,0])\n",
    "    totalNotional = position[1] + np.sum(impacts[:,1])\n",
    "    return totalExposure(totalMtm, totalNotional, addOnFactor)\n",
    "\n",
    "def psrConservative(position, impacts, addOnFactor):\n",
    "\n",
    "    # For each step, we calculate the exposure individually for each impact and add that to the total.\n",
    "    \n",
    "    total = 0\n",
    "    total += totalExposure(position[0], position[1], addOnFactor)\n",
    "\n",
    "    for i in range(len(impacts)):\n",
    "        total += totalExposure(impacts[i,0], impacts[i,1], addOnFactor)\n",
    "\n",
    "    return total \n",
    "\n",
    "def psrLinearisation(position, impacts, addOnFactor):\n",
    "\n",
    "    # We take the baseline position and for each subsequent impact, we take that exposure and \n",
    "    # subtract it from the original baseline position. (Read MXWiki for more detail)\n",
    "\n",
    "    total = 0\n",
    "    position_exposure = totalExposure(position[0], position[1], addOnFactor)\n",
    "    total += position_exposure\n",
    "\n",
    "    for i in range(len(impacts)):\n",
    "        total += totalExposure(position[0]+impacts[i,0], position[1]+impacts[i,1], addOnFactor) - position_exposure\n",
    "\n",
    "    return max(0,total)\n",
    "\n",
    "def psrAverages(position, impacts, addOnFactor, n):\n",
    "    \n",
    "    # This method is very similar to the linearisation approach.\n",
    "    \n",
    "    total = 0\n",
    "    position_exposure = totalExposure(position[0], position[1], addOnFactor)\n",
    "    total += position_exposure\n",
    "\n",
    "    for i in range(len(impacts)):\n",
    "        total += 1/n*(totalExposure(position[0]+n*impacts[i,0], position[1]+n*impacts[i,1], addOnFactor) - position_exposure)\n",
    "    \n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "def remove_outliers(data, threshold = 2):\n",
    "\n",
    "    # The growth in exposure from the baseline can be exceptionally high for a small number of trades (since we are going from 0% difference to, for instance, a 20% differnce depending on the impacts we use).\n",
    "    # This function removes the outliers that impact our analysis of the graph, by using standard mean and variance approaches\n",
    "\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    cleaned_data = data.copy()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if -(mean+threshold*std_dev) < data[i] < (mean+threshold*std_dev):\n",
    "            cleaned_data[i] = data[i]\n",
    "        else:\n",
    "            if i == 0:\n",
    "                neighbors = [data[j] for j in range(max(0, i+5), min(len(data), i+3)) if j != i]\n",
    "                cleaned_data[i] = np.median(neighbors)\n",
    "            elif i == len(data) - 1:\n",
    "                continue\n",
    "            else:\n",
    "                # Method: use median and neighbours\n",
    "                neighbors = [data[j] for j in range(max(0, i-2), min(len(data), i+3)) if j != i]\n",
    "                cleaned_data[i] = np.median(neighbors)\n",
    "    return cleaned_data\n",
    "    \n",
    "\n",
    "def exposure_simulation(n, baselineMTM, baselineNotional, mtmMin, mtmMax, notionalMin, notionalMax, addOnWidget, lin=True, cons=False, avg=False):\n",
    "\n",
    "    # here we want to obtain a graph showing the growth of the difference between baseline/brute force as number of trades increase\n",
    "    addOnVal = 0.005\n",
    "    baseline_position = [baselineMTM, baselineNotional]  \n",
    "\n",
    "    # Here, for each number n, we will take a new dataset (baseline and impacts) and calculate the exposure\n",
    "    # for each strategy by adding them to each respective list.\n",
    "    \n",
    "    bf_list = []\n",
    "    cons_list = []\n",
    "    lin_list = []\n",
    "    avg_list = []\n",
    "\n",
    "    for i in range(1,n):\n",
    "    \n",
    "        mtm_notional_matrix = np.zeros((i,2)) # Column 1 will be MTM, Column 2 will be Notional\n",
    "\n",
    "        for j in range(i):\n",
    "            mtm_notional_matrix[j,0] = random.randint(mtmMin,mtmMax)\n",
    "\n",
    "        for j in range(i):\n",
    "            mtm_notional_matrix[j,1] = random.randint(notionalMin, notionalMax)\n",
    "\n",
    "\n",
    "        bf_list.append(psrBruteForce(baseline_position, mtm_notional_matrix, addOnVal))\n",
    "        cons_list.append(psrConservative(baseline_position, mtm_notional_matrix, addOnVal))\n",
    "        lin_list.append(psrLinearisation(baseline_position, mtm_notional_matrix, addOnVal))\n",
    "        avg_list.append(psrAverages(baseline_position, mtm_notional_matrix, addOnVal, n))\n",
    "\n",
    "\n",
    "    # We calculate the percentage difference from the brute force approach using these lists\n",
    "    diff_cons = [(cons_list[i]-bf_list[i])/bf_list[i] * 100 for i in range(len(bf_list))]\n",
    "    diff_lin = [(lin_list[i]-bf_list[i])/bf_list[i] * 100 for i in range(len(bf_list))]\n",
    "    diff_avg = [(avg_list[i]-bf_list[i])/bf_list[i] * 100 for i in range(len(bf_list))]\n",
    "\n",
    "\n",
    "    # We then cleanse the dataset of its outliers\n",
    "    diff_cons = remove_outliers(diff_cons, 3)\n",
    "    diff_lin = remove_outliers(diff_lin, 3)\n",
    "    diff_avg = remove_outliers(diff_avg, 3)\n",
    "    \n",
    "    \n",
    "    #####################   POST-PROCESSING   #####################\n",
    "\n",
    "    x = np.arange(1,n)\n",
    "\n",
    "    plt.figure(figsize=(7, 3))\n",
    "    plt.grid(True)\n",
    "\n",
    "    if lin == True:\n",
    "        plt.plot(x[int(n/100):],diff_lin[int(n/100):],'r', label=\"Linearisation\")\n",
    "    \n",
    "    if cons == True:\n",
    "        plt.plot(x,diff_cons,'b', label=\"Conservative\")\n",
    "\n",
    "    if avg == True:\n",
    "        plt.plot(x,diff_avg,'g', label=\"Averages\")\n",
    "\n",
    "    plt.xlabel(\"# of trades\")\n",
    "    plt.ylabel(\"% Diff. from Brute Force\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96695a2e5a764eb7bfc8249f0bee62b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Play(value=20, description='n', interval=200, max=800, min=20, step=20), IntSlider(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.exposure_simulation(n, baselineMTM, baselineNotional, mtmMin, mtmMax, notionalMin, notionalMax, addOnWidget, lin=True, cons=False, avg=False)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "widgets.interact(exposure_simulation, n = widgets.Play(min = 20 , max = 800, step = 20, interval=200),baselineMTM = widgets.IntSlider(min=0,max=100000,step=500,value=1000,description=\"BaseMTM\"),\n",
    "         baselineNotional = widgets.IntSlider(min=0,max=5000,step=20,value=200,description=\"BaseNotional\"),\n",
    "         mtmMin = widgets.IntSlider(min=-20000,max=0,step=50,value=-2000,description=\"MTM Min\"),\n",
    "         mtmMax = widgets.IntSlider(min=0,max=20000,step=50,value=3000,description=\"MTM Max\"),\n",
    "         notionalMin = widgets.IntSlider(min=-2000,max=0,step=50,value=-1000,description=\"NotionalMin\"),\n",
    "         notionalMax = widgets.IntSlider(min=0,max=2000,step=50,value=1000,description=\"NotionalMax\"),\n",
    "         addOnWidget = widgets.FloatSlider(min=0,max=1,step=0.01,value=0.01,description=\"AddOnFactor\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
