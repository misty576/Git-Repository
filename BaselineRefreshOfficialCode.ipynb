{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Refresh Code Example\n",
    "\n",
    "In this code we show how to implement a baseline refresh for the different exposure methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6185e9089d464623bc891e8ec494f697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='# of Trades', min=1), IntSlider(value=5, description='R…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.exposure_simulation(n, m, addOn)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import tkinter\n",
    "\n",
    "def currentExposure(mtm):\n",
    "    return max(0,mtm)\n",
    "\n",
    "\n",
    "def addOn(notional, addOnFactor):\n",
    "    return notional*addOnFactor\n",
    "\n",
    "\n",
    "def totalExposure(mtm, notional, addOnFactor):\n",
    "    currExp = currentExposure(mtm)\n",
    "    currAddOn = addOn(notional, addOnFactor)\n",
    "\n",
    "    return currExp + currAddOn\n",
    "\n",
    "def psrBruteForce(position, impacts, addOnFactor, bf_list):\n",
    "    \n",
    "    total = 0\n",
    "    totalMtm = position[0]\n",
    "    totalNotional = position[1]\n",
    "    \n",
    "    total += totalExposure(totalMtm, totalNotional, addOnFactor)\n",
    "    bf_list.append(total)\n",
    "    \n",
    "    for i in range(len(impacts)):\n",
    "\n",
    "        totalMtm += impacts[i,0]\n",
    "        totalNotional += impacts[i,1]\n",
    "        total = totalExposure(totalMtm, totalNotional, addOnFactor)\n",
    "        bf_list.append(total)\n",
    "    \n",
    "    return bf_list\n",
    "\n",
    "\n",
    "def psrConservative(position, impacts, addOnFactor, cons_list):\n",
    "    total = 0\n",
    "    total += totalExposure(position[0], position[1], addOnFactor)\n",
    "    cons_list.append(total)\n",
    "\n",
    "    for i in range(len(impacts)):\n",
    "        total += totalExposure(impacts[i,0], impacts[i,1], addOnFactor)\n",
    "        cons_list.append(total)\n",
    "\n",
    "    return cons_list\n",
    "\n",
    "def psrLinearisation(position, impacts, addOnFactor, lin_list):\n",
    "    total = 0\n",
    "    position_exposure = totalExposure(position[0], position[1], addOnFactor)\n",
    "    total += position_exposure\n",
    "    lin_list.append(position_exposure)\n",
    "\n",
    "    for i in range(len(impacts)):\n",
    "        total += totalExposure(position[0]+impacts[i,0], position[1]+impacts[i,1], addOnFactor) - position_exposure\n",
    "        \n",
    "        # We implement the workaround as dicussed below\n",
    "        lin_list.append(max(0, total))\n",
    "\n",
    "        # lin_list.append(total)\n",
    "\n",
    "    return lin_list\n",
    "\n",
    "def psrAverages(position, impacts, addOnFactor, n, avg_list):\n",
    "    total = 0\n",
    "    position_exposure = totalExposure(position[0], position[1], addOnFactor)\n",
    "    total += position_exposure\n",
    "    avg_list.append(position_exposure)\n",
    "\n",
    "    for i in range(len(impacts)):\n",
    "        total += 1/n*(totalExposure(position[0]+n*impacts[i,0], position[1]+n*impacts[i,1], addOnFactor) - position_exposure)\n",
    "        avg_list.append(total)\n",
    "\n",
    "    return avg_list\n",
    "\n",
    "def remove_outliers(data, threshold = 2):\n",
    "\n",
    "    # The growth in exposure from the baseline can be exceptionally high for a small number of trades (since we are going from 0% difference to, for instance, a 20% differnce depending on the impacts we use).\n",
    "    # This function removes the outliers that impact our analysis of the graph, by using standard mean and variance approaches\n",
    "\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    cleaned_data = data.copy()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "\n",
    "        if -(mean+threshold*std_dev) < data[i] < (mean+threshold*std_dev):\n",
    "            cleaned_data[i] = data[i]\n",
    "        else:\n",
    "            if i == 0:\n",
    "                neighbors = [data[j] for j in range(max(0, i+5), min(len(data), i+3)) if j != i]\n",
    "                cleaned_data[i] = np.median(neighbors)\n",
    "            elif i == len(data) - 1:\n",
    "                continue\n",
    "            else:\n",
    "                # Method: use median and neighbours\n",
    "                neighbors = [data[j] for j in range(max(0, i-2), min(len(data), i+3)) if j != i]\n",
    "                cleaned_data[i] = np.median(neighbors)\n",
    "    return cleaned_data\n",
    "    \n",
    "\n",
    "def get_position_impacts(n):\n",
    "    \n",
    "    baseline_position = [400, 2000]\n",
    "    mtm_notional_matrix = np.zeros((n,2))\n",
    "\n",
    "    \n",
    "    for i in range(n):\n",
    "\n",
    "        mtm_notional_matrix[i,0] = random.randint(-200,200)\n",
    "        mtm_notional_matrix[i,1] = random.randint(0,250)\n",
    "\n",
    "    return [baseline_position, mtm_notional_matrix]\n",
    "\n",
    "position_impacts_state = {\"n\": 0, \"data\": None}\n",
    "\n",
    "def update_position_impacts(n):\n",
    "    global position_impacts_state\n",
    "    if position_impacts_state[\"n\"] != n:\n",
    "        position_impacts_state[\"n\"] = n\n",
    "        position_impacts_state[\"data\"] = get_position_impacts(n)\n",
    "\n",
    "\n",
    "def get_position_impacts_test(n=4):\n",
    "\n",
    "    #baseline_position = [400, 2000]\n",
    "    #mtm_notional_matrix = np.zeros((n,4))\n",
    "\n",
    "    #mtm_notional_matrix[0,0] = 300\n",
    "    #mtm_notional_matrix[1,0] = -400\n",
    "    #mtm_notional_matrix[2,0] = 400\n",
    "    #mtm_notional_matrix[3,0] = -400\n",
    "\n",
    "    #mtm_notional_matrix[0,1] = 1000\n",
    "    #mtm_notional_matrix[1,1] = 1000\n",
    "    #mtm_notional_matrix[2,1] = 1000\n",
    "    #mtm_notional_matrix[3,1] = 0\n",
    "\n",
    "    baseline_position = [500, 1500]\n",
    "    mtm_notional_matrix = np.zeros((n,4))\n",
    "\n",
    "    mtm_notional_matrix[1,0] = -250\n",
    "    mtm_notional_matrix[3,0] = 300\n",
    "    mtm_notional_matrix[2,0] = -100\n",
    "    mtm_notional_matrix[0,0] = -400\n",
    "\n",
    "    mtm_notional_matrix[1,1] = 800\n",
    "    mtm_notional_matrix[3,1] = 1200\n",
    "    mtm_notional_matrix[2,1] = 500\n",
    "    mtm_notional_matrix[0,1] = 0\n",
    "\n",
    "\n",
    "    return [baseline_position, mtm_notional_matrix]\n",
    "\n",
    "\n",
    "def exposure_simulation(n,m, addOn):\n",
    "    update_position_impacts(n)\n",
    "    baseline_position, mtm_notional_matrix = position_impacts_state[\"data\"]\n",
    "    \n",
    "    addOnVal = addOn\n",
    "\n",
    "    bf_list = []\n",
    "    cons_list = []\n",
    "    lin_list = []\n",
    "    avg_list = []\n",
    "\n",
    "\n",
    "    for i in range(int(n/m)):\n",
    "\n",
    "        [bf_list, cons_list, lin_list, avg_list] = [psrBruteForce(baseline_position, mtm_notional_matrix[m*i:m*(i+1),:], addOnVal, bf_list),\n",
    "                                                    psrConservative(baseline_position, mtm_notional_matrix[m*i:m*(i+1),:], addOnVal, cons_list),\n",
    "                                                    psrLinearisation(baseline_position, mtm_notional_matrix[m*i:m*(i+1),:], addOnVal, lin_list),\n",
    "                                                    psrAverages(baseline_position, mtm_notional_matrix[m*i:m*(i+1),:], addOnVal, m, avg_list)]\n",
    "        \n",
    "        mtmRefresh = baseline_position[0]+np.sum(mtm_notional_matrix[m*i:m*(i+1),0])\n",
    "        notionalRefresh = baseline_position[1] + np.sum(mtm_notional_matrix[m*i:m*(i+1),1])\n",
    "        \n",
    "        # We introduce the workaround as discussed below\n",
    "        baseline_position = [max(0, mtmRefresh), notionalRefresh]\n",
    "\n",
    "        # baseline_position = [mtmRefresh, notionalRefresh]\n",
    "        print(\"Baseline after refresh \" + str(i+1) + \": \", baseline_position)\n",
    "\n",
    "    x = np.linspace(0, n+int(n/m)-1, n+int(n/m))\n",
    "\n",
    "\n",
    "    if n % m == 0:\n",
    "        \n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.grid(True)\n",
    "        plt.plot(x, bf_list, 'b', label = \"BF\")\n",
    "        plt.plot(x, cons_list, 'r', label = \"Conservative\")\n",
    "        plt.plot(x, lin_list, 'g', label = \"Linearisation\")\n",
    "        plt.plot(x, avg_list, 'y', label = \"Averages\")\n",
    "        plt.xlabel(\"Trade Number\")\n",
    "        plt.ylabel(\"Exposure\")\n",
    "\n",
    "\n",
    "        for i in range(int(n/m)):\n",
    "\n",
    "            vline_x = (i+1)*(m+1)\n",
    "            ymin, ymax = plt.ylim()\n",
    "            plt.axvline(vline_x, color='k', linestyle='--')\n",
    "            vline_x2 = (i+1)*(m+1)-1\n",
    "            ymin2, ymax2 = plt.ylim()\n",
    "            plt.axvline(vline_x2, color='r', linestyle='--')\n",
    "            plt.text(vline_x, ymax + (ymax - ymin)*0.025, 'RF', ha=\"center\", va = \"bottom\", color=\"k\")\n",
    "            plt.text(vline_x2, ymax2 + (ymax2 - ymin2)*0.025, '↻', ha=\"center\", va = \"bottom\", color=\"r\")\n",
    "\n",
    "        vline_start = 0\n",
    "        ymin3, ymax3 = plt.ylim()\n",
    "        plt.axvline(vline_start, color='b', linestyle='--')\n",
    "        plt.text(vline_start, ymax3 + (ymax3 - ymin3)*0.025, 'Base', ha=\"center\", va = \"bottom\", color=\"b\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Impacts Matrix \\n\", mtm_notional_matrix)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(\"BF list \", bf_list)\n",
    "        print(\"Lin List\", lin_list)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(\"Conservative List\", cons_list)\n",
    "        print(\"Average List\", avg_list)\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(\"ERROR: you must choose n and m such that m divides n (ie. n / m is a whole number)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interact(exposure_simulation,\n",
    "         n=widgets.IntSlider(min=1, max=100, step=1, value=10, description=\"# of Trades\"),\n",
    "         m=widgets.IntSlider(min=1, max=100, step=1, value =5, description=\"Refresh Cycle\"),\n",
    "          addOn = widgets.FloatSlider(min=0,max=1,step=0.01,value=0.01,description=\"AddOnFactor\"),\n",
    "         )\n",
    "\n",
    "#exposure_simulation(100,25,0.1)\n",
    "\n",
    "# There are two special cases where the Linear approach goes below the Brute Force approach.\n",
    "\n",
    "# When the refresh takes us to a new basleine position where the mtm is negative. This in turn affects the linearisation. To see this, note \n",
    "# how the linear approach calcuates the differnce between a new position and the baseline refresh individaully. If the baseline is negative\n",
    "# what happens is it will not grow as fast as the brute force does, and so brute force will go above. \n",
    "\n",
    "# When the current position is close to zero and an incoming contract causes the new position to be negatvie. The brute force method will go to zero \n",
    "# however the linear method will end up going further below and become negative.\n",
    "\n",
    "# To get around these two problems, we have two implement two things in the code.\n",
    "\n",
    "# 1 .The first (and easy) workaround is to stop the refresh from setting a negative baseline. One easy solution is to just set the new MTM to 0 (chat to Rory about this)\n",
    "\n",
    "\n",
    "# 2 .The second workaround is to stop the linear graph from going below when the exposure is close to zero. How can one do this?\n",
    "\n",
    "# Let's say we are calculating the linear exposure: p = 1 , x1 = x2 = -1\n",
    "# we get for BF : rho( p + x1 + x2 ) = 0 \n",
    "\n",
    "# but for Linear: rho(p) + ( rho(p+x1) - rho(p) ) + ( rho(p+x2) - rho(p) ) = -1 . \n",
    "\n",
    "# What we can do here is keep a tally of the total exposure of the linear approach. So if the next difference delta_i is going\n",
    "# to cause the sum to go to below zero, then we can just make the linear exposure return max(0, total_sum). This should counteract the error in question.\n",
    "\n",
    "# INTERESTING SITUATION\n",
    "# Now let the notional be arbitrarily large and the mtm to be sort of close to zero. If we have an addon factor that is quite large (say 0.5) what happens is the Linearisation \n",
    "# approach will sink to zero (due to the way in which it is defined), and brute force will stay positive since the Notional* AddOnFactor always adds on each time (though it should sink to zero)\n",
    "# Note that on the graph if we sink this down to zero, the BF and Linear will merge!\n",
    "\n",
    "# SOLUTION: The simple resolution is avoidance: don't run a simulation where there is a high possibility the exposure will tend to zero at some point (set high MTM's with lower notionals). \n",
    "# Or, if there is a piece of code that does a dynamic refresh when the exposure is closing in on zero (and the next impact would ultimately \n",
    "# send the exposure to a negative number), or make the graphs behave differently until it finally moves away from that point\n",
    "# SOLUTION: Another solution would be more frequent refreshes. Therefore, if there is a risk of the linear going under, the baseline refreshes so it doesn't happen for too long."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
